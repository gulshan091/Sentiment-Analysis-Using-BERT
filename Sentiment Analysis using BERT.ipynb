{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp39-cp39-win_amd64.whl (2.1 MB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Gulshan\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: sympy in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-win_amd64.whl (266 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2021.10.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gulshan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Gulshan\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification:\n",
    "This line imports classes from the transformers library,\n",
    "which is used for working with pre-trained models in natural language processing tasks like text classification, \n",
    "translation, and more.\n",
    "\n",
    "AutoTokenizer: This class is used for loading tokenizers for various pre-trained models.\n",
    "AutoModelForSequenceClassification: This class is used for loading pre-trained models designed \n",
    "for sequence classification tasks.\n",
    "import torch:\n",
    "This line imports the torch library, which is the PyTorch deep learning framework. It provides tools \n",
    "for building and training neural networks.\n",
    "\n",
    "import requests:\n",
    "This line imports the requests library, which is used to make HTTP requests to web servers. \n",
    "It's commonly used to retrieve data from URLs.\n",
    "\n",
    "from bs4 import BeautifulSoup:\n",
    "This line imports the BeautifulSoup class from the bs4 (Beautiful Soup 4) library. \n",
    "Beautiful Soup is a library used for web scraping and parsing HTML documents.\n",
    "\n",
    "import re:\n",
    "This line imports the built-in re module, which provides support for regular expressions. \n",
    "Regular expressions are used for pattern matching and manipulation of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7608f90e06a4068a791ecc782b48327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gulshan\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Gulshan\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be105efbe9247759a86eb316d5e3ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317c9fbc50294b6095c8de19c94c07d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bc69b44a6e4739b1a015a9aab5c215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoTokenizer class is a part of the transformers library, which is used for working with pre-trained models in natural language processing. Specifically, the AutoTokenizer class is designed to load tokenizers for various pre-trained models. Let's explore its purpose and functionality:\n",
    "\n",
    "Purpose of AutoTokenizer:\n",
    "Tokenization is the process of splitting text into individual words or subwords, which are often referred to as \"tokens.\" Tokenization is a crucial step in natural language processing tasks as it converts raw text into a format that machine learning models can understand and process.\n",
    "\n",
    "The AutoTokenizer class simplifies the process of loading tokenizers for specific pre-trained models. It automatically selects the appropriate tokenizer based on the model architecture or type specified in its arguments.\n",
    "\n",
    "Key Features and Methods:\n",
    "\n",
    "AutoTokenizer.from_pretrained(model_identifier): This static method is used to load a tokenizer for a specific pre-trained model. The model_identifier parameter is a string that represents the model's identifier or name. It can be a model name from the Hugging Face Model Hub or a local path to a model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e61cce9f464d60b6677cb35bfa1849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoModelForSequenceClassification class is a component of the transformers library, designed to facilitate working with pre-trained models for sequence classification tasks. Let's delve into its purpose and functionality:\n",
    "\n",
    "Purpose of AutoModelForSequenceClassification:\n",
    "Sequence classification is a type of natural language processing task where the goal is to classify a sequence of text (such as a sentence or a document) into one or more predefined categories or classes. This could involve sentiment analysis, topic categorization, intent recognition, and more.\n",
    "\n",
    "The AutoModelForSequenceClassification class simplifies the process of loading pre-trained models that are specifically designed for sequence classification tasks.\n",
    "\n",
    "Key Features and Methods:\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(model_identifier): This static method is used to load a pre-trained model for sequence classification. The model_identifier parameter is a string that represents the model's identifier or name. It can be a model name from the Hugging Face Model Hub or a local path to a model directory.\n",
    "\n",
    "Once you have a model instance, you can use its methods to perform inference on sequences, make predictions, and fine-tune the model for specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Encode and Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer.encode('It was good but couldve been better. Great', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 10197, 10140, 12050, 10502, 12296, 10598, 10662, 16197,   119,\n",
       "         11838,   102]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer:\n",
    "Imagine a tool that can turn sentences into special codes. This tool is the \"tokenizer.\" You might have made it using the AutoTokenizer tool from the transformers toolbox.\n",
    "\n",
    "Encode:\n",
    "The \"encode\" action is like translating a sentence into a secret language that the computer understands. For instance, the sentence \"It was good but could've been better. Great\" becomes a series of special numbers (token IDs) that the computer can work with.\n",
    "\n",
    "return_tensors='pt':\n",
    "Think of this as a preference you're telling the computer. You're saying, \"Please give me these special numbers in a format that the PyTorch toolbox understands (PyTorch tensors). If you don't tell me this, you'll get the numbers in a different form, like a list.\n",
    "\n",
    "Result:\n",
    "The outcome of the code line (which is stored in the \"tokens\" box) is a set of special numbers (PyTorch tensors). Each number represents a word or part of a word from your original sentence. You can think of these numbers as a secret code that you can give to a pre-trained model. This model will then use these codes to understand the meaning of your sentence, like figuring out if the sentence is positive or negative.\n",
    "\n",
    "So, in simple terms, this line of code helps you turn a sentence into a code that a computer model can understand and use to understand your text's meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] it was good but couldve been better. great [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens1[0])\n",
    "#we are using the [0] index so that we can pass through list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.7768, -1.2353,  1.4419,  1.9804,  0.4584]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7768, -1.2353,  1.4419,  1.9804,  0.4584]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits))+1\n",
    "#got ethe rating as 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = tokenizer.encode('Meh, it was okay', return_tensors='pt')\n",
    "tokenizer.decode(tokens2[0])\n",
    "result2 = model(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.9936,  1.6286,  2.9420, -0.1614, -2.8794]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9936,  1.6286,  2.9420, -0.1614, -2.8794]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result2.logits))+1\n",
    "#got ethe rating as 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collect Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.yelp.com/biz/social-brew-cafe-pyrmont')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "regex = re.compile('.*comment.*')\n",
    "results = soup.find_all('p', {'class':regex})\n",
    "reviews = [result.text for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the requests, BeautifulSoup, and re libraries to scrape and extract text data from a Yelp web page. Let's break down each step:\n",
    "\n",
    "r = requests.get('https://www.yelp.com/biz/social-brew-cafe-pyrmont'):\n",
    "This line sends an HTTP GET request to the URL 'https://www.yelp.com/biz/social-brew-cafe-pyrmont' using the requests.get() function. The response from the server is stored in the variable r.\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser'):\n",
    "This line creates a BeautifulSoup object named soup to parse the HTML content of the web page. The r.text part of the code extracts the HTML content from the response, and 'html.parser' specifies the parser to be used for parsing the HTML.\n",
    "\n",
    "regex = re.compile('.*comment.*'):\n",
    "This line compiles a regular expression pattern using the re.compile() function. The pattern .*comment.* is used to match any text that contains the word \"comment\" in it.\n",
    "\n",
    "results = soup.find_all('p', {'class': regex}):\n",
    "This line uses the find_all() method of the soup object to find all <p> (paragraph) HTML elements with a class attribute that matches the regular expression pattern. In this case, it's looking for elements with class names that contain the word \"comment.\" The matched elements are stored in the results list.\n",
    "\n",
    "reviews = [result.text for result in results]:\n",
    "This line creates a list comprehension that iterates through the results list, which contains the matched HTML elements. For each element, it extracts the text content using the .text attribute and adds it to the reviews list. This effectively collects the text content of the comments found on the web page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some of the best Milkshakes me and my daughter ever tasted. MMMMMM HMMMMMMMM.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some of the best Milkshakes me and my daughter ever tasted. MMMMMM HMMMMMMMM.',\n",
       " \"Six of us met here for breakfast before our walk to Manly. We were enjoying visiting with each other so much that I apologize for not taking any photos. We all enjoyed our food, as well as our coffee and tea drinks.We were greeted immediately by a friendly server asking if we would like to sit inside or out. We said we would like inside, but weren't exactly sure how many were joining us yet- at least 4. We were told this was no problem, the more the merrier. A few minutes later when 4 more joined our party and we explained to the server we had 6, he just quickly switched our table. I really enjoyed my serenity tea, just what I needed after a long flight in from Sfo that morning. Everyone else were more interested in the lattes for expresso drinks. All said they were hot and delicious. 2 of us ordered the avo on toast. So yummy with the beetroot... I will start adding this to mine now at home, and have fond memories for my trip to Sydney. 2 friends ordered the salmon Benedict- saying it was delicious, and their go to every time they come here. 2 friends had a breakfast sandwich- I'm not sure of the name. It did look delicious. Adorable cafe, friendly staff, clean restroomsVery popular with the locals. I plan to come back the next time I'm in Sydney\",\n",
       " 'Great place with delicious food and friendly staff. It is small but has outdoor seating and a relaxed ambiance. Perfect place to enjoy a cup of coffee. I am visiting Sydney for the first time but this place seems like is a local favorite.',\n",
       " 'Great food amazing coffee and tea. Short walk from the harbor. Staff was very friendly',\n",
       " \"It was ok. Had coffee with my friends. I'm new in the area, still need to discover new places.\",\n",
       " \"Ricotta hot cakes! These were so yummy. I ate them pretty fast and didn't share with anyone because they were that good ;). I ordered a green smoothie to balance it all out. Smoothie was a nice way to end my brekkie at this restaurant. Others with me ordered the salmon Benedict and the smoked salmon flatbread. They were all delicious and all plates were empty. Cheers!\",\n",
       " 'Great staff and food. \\xa0Must try is the pan fried Gnocchi! \\xa0The staff were really friendly and the coffee was good as well',\n",
       " \"We came for brunch twice in our week-long visit to Sydney. Everything on the menu not only sounds delicious, but is really tasty. It really gave us a sour taste of how bad breaky is in America with what's so readily available in Sydney! \\xa0Both days we went were Saturdays and there was a bit of a wait to be seated, the cafe is extremely busy for both dine-in and take-away. Service is fairly quick and servers are all friendly. The location is in Surrey Hills a couple blocks away from the bustling touristy Darling Harbor.The green smoothie is very tasty and refreshing. We tried the smoked salmon salad, the soft shell crab tacos, ricotta hotcakes, and the breaky sandwich. All were delicious, well seasoned, and a solid amount of food for the price. A definite recommend for anyone's trip into Sydney!\",\n",
       " 'I came to Social brew cafe for brunch while exploring the city and on my way to the aquarium. I sat outside. The service was great and the food was good too!I ordered smoked salmon, truffle fries, black coffee and beer.',\n",
       " \"It was ok. The coffee wasn't the best but it was fine. The relish on the breakfast roll was yum which did make it sing. So perhaps I just got a bad coffee but the food was good on my visit.\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load Reviews into DataFrame and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(reviews), columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some of the best Milkshakes me and my daughter ever tasted. MMMMMM HMMMMMMMM.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score(df['review'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['review'].apply(lambda x: sentiment_score(x[:512]))\n",
    "#nlp has limited the number of tokens equal to 512 thats why we are using [:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some of the best Milkshakes me and my daughter...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Six of us met here for breakfast before our wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great place with delicious food and friendly s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great food amazing coffee and tea. Short walk ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was ok. Had coffee with my friends. I'm new...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ricotta hot cakes! These were so yummy. I ate ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Great staff and food. Â Must try is the pan fri...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We came for brunch twice in our week-long visi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I came to Social brew cafe for brunch while ex...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It was ok. The coffee wasn't the best but it w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Some of the best Milkshakes me and my daughter...          5\n",
       "1  Six of us met here for breakfast before our wa...          4\n",
       "2  Great place with delicious food and friendly s...          5\n",
       "3  Great food amazing coffee and tea. Short walk ...          5\n",
       "4  It was ok. Had coffee with my friends. I'm new...          3\n",
       "5  Ricotta hot cakes! These were so yummy. I ate ...          5\n",
       "6  Great staff and food. Â Must try is the pan fri...          5\n",
       "7  We came for brunch twice in our week-long visi...          4\n",
       "8  I came to Social brew cafe for brunch while ex...          5\n",
       "9  It was ok. The coffee wasn't the best but it w...          3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great food amazing coffee and tea. Short walk from the harbor. Staff was very friendly'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
